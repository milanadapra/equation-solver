{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Computing - rač. vežba 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacija sistema za optičko prepoznavanje karaktera (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokom prethodne četiri vežbe smo implementirali \"ceo\" sistem za optičko prepoznavanje karaktera, ali smo u tom procesu zanemarili mnoge probleme koje OCR u realnom okruženju sa sobom nosi. Cilj ovih vežbi jeste identifikacija i rešavanje tih problema.\n",
    "\n",
    "OCR sistemi vrše optičko prepoznavanje tekstualnih sadržaja sa fotografija, gde je fotografija ulazni parametar sistema. Tačnost i performantnost sistema će u mnogome zavisiti od pretpostavke o ulaznoj fotografiji. Pošto se takva fotografija pravi u realnom okruženju, normalno je za očekivati dosta spoljnih uticaja. Ukoliko pretpostavimo da ulazna fotografija neće biti pod uticajem određenog broja faktora iz okruženja sistem može da se pojednostavi. Recimo, kamere u industijskim pogonima prave fotografije u okruženju u kome se nivo osvetljenja može kontrolisati, uređaj za fotografisanje je uvek isti i pravi fotografije koje su \"sličnog\" oblika.\n",
    "\n",
    "Do sada smo OCR sistem implementirali uz pretpostavku da je fotografija idealna i da je tekstualni sadržaj na njoj u prost. Međutim, to najčešće nije slučaj. Ulazna fotografija će obično izgledati ovako:\n",
    "<img src=\"images/cifre.jpg\"></img>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import potrebnih biblioteka\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 16, 12 # za prikaz većih slika i plotova, zakomentarisati ako nije potrebno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrada digitalne slike\n",
    "Obrada digitalne slike predstavlja prvi skup aktivnosti u sistemu za OCR. Cilj ovog skupa aktivnosti jeste prilagođavanje ulazne fotografije da bi se nad njom mogla vršiti analiza sadržaja. Obrada digitalne slike može biti dosta složen proces, pošto bi on trebao biti u stanju da obradi bilo kakvu ulaznu fotografiju. Proces analize digitalne slike će biti mnogo jednostavniji ukoliko se fotografija prethodno dobro obradi i ukloni vecina suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Funkcionalnost implementirana u V1\n",
    "def load_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "def image_bin(image_gs):\n",
    "    ret,image_bin = cv2.threshold(image_gs, 127, 255, cv2.THRESH_BINARY)\n",
    "    return image_bin\n",
    "def image_bin_adaptive(image_gs):\n",
    "    image_bin = cv2.adaptiveThreshold(image_gs, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 35, 10)\n",
    "    return image_bin\n",
    "def invert(image):\n",
    "    return 255-image\n",
    "def display_image(image, color= False):\n",
    "    if color:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, 'gray')\n",
    "def dilate(image):\n",
    "    kernel = np.ones((3,3)) # strukturni element 3x3 blok\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "def erode(image):\n",
    "    kernel = np.ones((3,3)) # strukturni element 3x3 blok\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "#Funkcionalnost implementirana u V2\n",
    "def resize_region(region):\n",
    "    resized = cv2.resize(region,(28,28), interpolation = cv2.INTER_NEAREST)\n",
    "    return resized\n",
    "def scale_to_range(image):\n",
    "    return image / 255\n",
    "def matrix_to_vector(image):\n",
    "    return image.flatten()\n",
    "def prepare_for_ann(regions):\n",
    "    ready_for_ann = []\n",
    "    for region in regions:\n",
    "        ready_for_ann.append(matrix_to_vector(scale_to_range(region)))\n",
    "    return ready_for_ann\n",
    "def convert_output(outputs):\n",
    "    return np.eye(len(outputs))\n",
    "def winner(output):\n",
    "    return max(enumerate(output), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuniformna osvetljenost fotografije\n",
    "Prva aktivnost u OCR sistemu jeste obrada digitalne slike, odnosno segmentacija. Cilj segmentacije jeste klasifikovanje piksela fotografije u one koji pripadaju sadržaju i one koji pripadaju pozadini. Do sada smo za segmentaciju koristili metode bazirane na računanju praga - <b><i>threshold</i></b>. Ukoliko se za celu fotografiju pronađe jedan prag segmentacije, problem se javlja ako su delovi fotografije osetno manje ili više osvetljeni od ostatka fotografije. Ovaj problem se može rešiti uz korišćenje adaptivnog threshold-a. Na taj način se može rešiti problem neuniformne osvetljenosti fotografije, koji je bio prisutan i na prethodnom primeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# učitavanje digitalne slike\n",
    "image_color = load_image('images/cifre2.jpg')\n",
    "# formiranje binarne slike\n",
    "img = image_bin(image_gray(image_color))\n",
    "display_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Šum na fotografiji nakon segmentacije\n",
    "Proces segmentacije će pokušati da klasifikuje piksele tako da ih obeleži da pripadaju sadržaju ili pozadini, ali ne mora da znači da će u tome biti 100% uspešan. Na fotografiji koja je rezultat procesa segmentacije može postojati šum koji može znatno otežati analizu ovakve fotografije u narednim koracima OCR-a. Zbog toga je takav šum potrebno otkloniti u što većoj meri u ovim ranim fazama.\n",
    "\n",
    "#Uklanjanje šuma\n",
    "U narednom odeljku je prikazana jedna metoda uklanjanja šuma. Nad fotografijom sa belom pozadinom i crnim tekstom izvršena je dilatacija kako bi se crne površine smanjile i uklonio potencijalni šum, a nakon toga smo erozijom proširili crne površine da bi ih vratili u prethodno stanje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uklanjanje šuma\n",
    "def remove_noise(binary_image):\n",
    "    ret_val = erode(dilate(binary_image))\n",
    "    ret_val = invert(ret_val)\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza digitalne slike\n",
    "Analiza digitalne slike počinje kreiranjem skupa regiona(kontura) sa binarne slike.\n",
    "\n",
    "###### * NAPOMENA: OpenCV po default-u vrši selektovanje belih površina na crnoj pozadini i sliku je potrebno postaviti u taj oblik pre pozivanja metode FindContours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takav skup regiona je potrebno analizirati i izvršiti njihovo prepoznavanje posredstvom veštačke neuronske mreže. Problem predstavlja činjenica da region ne mora izgledati uvek isto, iako predstavlja isti karakter. Jedan primer takve situacije jeste rotacija."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zarotirani simboli na fotografiji\n",
    "Svaki region se skalira na dimenzije 28x28 i formira matricu, a nakon toga se pretvara u vektor od 784 elementa. Očigledno je da će takva matrica izgledati drugačije ukoliko je region zarotiran, što će rezultovati činjenicom da ćemo na ulaz neuronske mreže dovesti ulazni vektor koji će jako loše opisivati region koji bi on trebalo da predstavlja. Posledica će biti loša predikcija od strane veštačke neuronske mreže. Zbog toga je regione potrebno zarotirati tako da se oni postave u prirodan položaj."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 1\n",
    "Tačke regiona je potrebno rotirati oko tačke <b>(c<sub>x</sub>, c<sub>y</sub>)</b> za zadati ugao <b>(α = π/2-|θ|)</b> gde su (c<sub>x</sub>, c<sub>y</sub> i theta) parametri dobijeni iz osobina regiona. Na ovaj način treba da se dobiju slike regiona koje su ‘relativno’ vertikalne.\n",
    "\n",
    "Formula za rotiranje tačke sa koordinatama (x,y) za ugao α oko tačke sa koordinatama (c<sub>x</sub>, c<sub>y</sub>):\n",
    "<img src=\"images/rotacijaFormula.jpg\"></img>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO 1 - Rotiranje regiona\n",
    "def rotate_regions(contours,angles,centers,sizes):\n",
    "    '''Funkcija koja vrši rotiranje regiona oko njihovih centralnih tačaka\n",
    "    Args:\n",
    "        contours: skup svih kontura [kontura1, kontura2, ..., konturaN]\n",
    "        angles:   skup svih uglova nagiba kontura [nagib1, nagib2, ..., nagibN]\n",
    "        centers:  skup svih centara minimalnih pravougaonika koji su opisani \n",
    "                  oko kontura [centar1, centar2, ..., centarN]\n",
    "        sizes:    skup parova (height,width) koji predstavljaju duzine stranica minimalnog\n",
    "                  pravougaonika koji je opisan oko konture [(h1,w1), (h2,w2), ...,(hN,wN)]\n",
    "    Return:\n",
    "        ret_val: rotirane konture'''\n",
    "    ret_val = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "                \n",
    "        angle = angles[idx]\n",
    "        cx,cy = centers[idx]\n",
    "        height, width = sizes[idx]\n",
    "        if width<height:\n",
    "            angle+=90\n",
    "            \n",
    "        # Rotiranje svake tačke regiona oko centra rotacije\n",
    "        alpha = np.pi/2 - abs(np.radians(angle))\n",
    "        region_points_rotated = np.ndarray((len(contour), 2), dtype=np.int16)\n",
    "        for i, point in enumerate(contour):\n",
    "            x = point[0]\n",
    "            y = point[1]\n",
    "            \n",
    "            #TODO 1 - izračunati koordinate tačke nakon rotacije\n",
    "            \n",
    "            \n",
    "            \n",
    "            region_points_rotated[i] = [rx,ry]\n",
    "        ret_val.append(region_points_rotated)\n",
    "        \n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simboli koji je sastoje iz više regiona\n",
    "Činjenica da se jedan simbol ne mora sastojati iz samo jednog regiona nama može predstavljati problem (npr. slova i,j,ž,ć,...). Zbog toga je potrebno izvršiti spajanje kukica i kvačica u okolini simbola pre slanja podataka na predikciju neuronskoj mreži.\n",
    "\n",
    "# TODO 2\n",
    "Spojiti kukice i kvačice sa osnovnim slovima.\n",
    "<img src=\"images/slovo.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions found:  10\n",
      "TODO 2 Test - Passed\n"
     ]
    }
   ],
   "source": [
    "# TODO 2\n",
    "def merge_regions(contours):\n",
    "    '''Funkcija koja vrši spajanje kukica i kvačica sa osnovnim karakterima\n",
    "    Args:\n",
    "        contours: skup svih kontura (kontura - niz tacaka bele boje)\n",
    "    Return:\n",
    "        ret_val: skup kontura sa spojenim kukicama i kvacicama'''\n",
    "    ret_val = []\n",
    "    merged_index = [] #lista indeksa kontura koje su već spojene sa nekim\n",
    "\n",
    "    for i,contour1 in enumerate(contours): #slova\n",
    "        if i in merged_index:\n",
    "            continue\n",
    "        min_x1 = min(contour1[:,0])\n",
    "        max_x1 = max(contour1[:,0])\n",
    "        min_y1 = min(contour1[:,1])\n",
    "        max_y1 = max(contour1[:,1])\n",
    "        for j,contour2 in enumerate(contours): #kukice\n",
    "            if j in merged_index or i == j:\n",
    "                continue\n",
    "            min_x2 = min(contour2[:,0])\n",
    "            max_x2 = max(contour2[:,0])\n",
    "            min_y2 = min(contour2[:,1])\n",
    "            max_y2 = max(contour2[:,1])\n",
    "            \n",
    "            #TODO 2 - izvršiti spajanje kukica iznad slova\n",
    "            #spajanje dva niza je moguće obaviti funkcijom np.concatenate((contour1,contour2))\n",
    "           \n",
    "            \n",
    "                    \n",
    "    #svi regioni koji se nisu ni sa kim spojili idu u listu kontura, bez spajanja\n",
    "    for idx,contour in enumerate(contours):\n",
    "        if idx not in merged_index:\n",
    "            ret_val.append(contour)\n",
    "        \n",
    "    return ret_val\n",
    "\n",
    "\n",
    "\n",
    "# TODO 2 - TEST\n",
    "image_test2_original = load_image('images/kukice.jpg')\n",
    "image_test2 = remove_noise(image_bin(image_gray(image_test2_original)))\n",
    "img2, contours_borders2, hierarchy2 = cv2.findContours(image_test2.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "contours2 = []\n",
    "for contour2 in contours_borders2:\n",
    "    center, size, angle = cv2.minAreaRect(contour2)\n",
    "    xt,yt,h,w = cv2.boundingRect(contour2)\n",
    "    region_points2 = []\n",
    "    for i in range (xt,xt+h):\n",
    "        for j in range(yt,yt+w):\n",
    "            dist = cv2.pointPolygonTest(contour2,(i,j),False)\n",
    "            if dist>=0 and image_test2[j,i]==255: # da li se tacka nalazi unutar konture?\n",
    "                region_points2.append([i,j])\n",
    "    contours2.append(np.asarray(region_points2))\n",
    "contour_count = merge_regions(contours2)\n",
    "print \"Regions found: \",len(contour_count)\n",
    "if len(contour_count) == 10:\n",
    "    print \"TODO 2 Test - Passed\"\n",
    "else:\n",
    "    print \"TODO 2 Test - Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 3\n",
    "U nastavku se nalazi funkcija za selekciju regiona od interesa koja nam je poznata sa prethodnih vežbi, a koja je sada proširena tako da vrši rotaciju svih regiona i spajanje kukica i kvačica iznad slova pozivanjem funkcija iz prethodna dva zadatka.\n",
    "\n",
    "Nakon spajanja kukica i kvačica na red dolazi skaliranje regiona na dimenzije 28x28. Region je sada niz tačaka čije su koordinate apsolutne koordinate na fotografiji sa koje su regioni preuzeti. Kako bi se isekao pravougaonik oko regiona potrebno je proći kroz sve tačke regiona i koordinate svake od njih prebaciti iz apsolutnih u relativne koordinate u odnosu na poziciju tačke unutar regiona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO 3\n",
    "def select_roi(image_orig, image_bin):\n",
    "    \n",
    "    img, contours_borders, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    contours = []\n",
    "    contour_angles = []\n",
    "    contour_centers = []\n",
    "    contour_sizes = []\n",
    "    for contour in contours_borders:\n",
    "        center, size, angle = cv2.minAreaRect(contour)\n",
    "        xt,yt,h,w = cv2.boundingRect(contour)\n",
    "\n",
    "        region_points = []\n",
    "        for i in range (xt,xt+h):\n",
    "            for j in range(yt,yt+w):\n",
    "                dist = cv2.pointPolygonTest(contour,(i,j),False)\n",
    "                if dist>=0 and image_bin[j,i]==255: # da li se tacka nalazi unutar konture?\n",
    "                    region_points.append([i,j])\n",
    "        contour_centers.append(center)\n",
    "        contour_angles.append(angle)\n",
    "        contour_sizes.append(size)\n",
    "        contours.append(region_points)\n",
    "    \n",
    "    #Postavljanje kontura u vertikalan polozaj\n",
    "    contours = rotate_regions(contours, contour_angles, contour_centers, contour_sizes)\n",
    "    \n",
    "    #spajanje kukica i kvacica\n",
    "    contours = merge_regions(contours)\n",
    "    \n",
    "    regions_dict = {}\n",
    "    for contour in contours:\n",
    "    \n",
    "        min_x = min(contour[:,0])\n",
    "        max_x = max(contour[:,0])\n",
    "        min_y = min(contour[:,1])\n",
    "        max_y = max(contour[:,1])\n",
    "\n",
    "        region = np.zeros((max_y-min_y+1,max_x-min_x+1), dtype=np.int16)\n",
    "        for point in contour:\n",
    "            x = point[0]\n",
    "            y = point[1]\n",
    "            \n",
    "             # TODO 3 - koordinate tacaka regiona prebaciti u relativne koordinate\n",
    "            '''Pretpostavimo da gornja leva tačka regiona ima apsolutne koordinate (100,100).\n",
    "            Ako uzmemo tačku sa koordinatama unutar regiona, recimo (105,105), nakon\n",
    "            prebacivanja u relativne koordinate tačka bi trebala imati koorinate (5,5) unutar\n",
    "            samog regiona.\n",
    "            '''\n",
    "\n",
    "\n",
    "        \n",
    "        regions_dict[min_x] = [resize_region(region), (min_x,min_y,max_x-min_x,max_y-min_y)]\n",
    "        \n",
    "    sorted_regions_dict = collections.OrderedDict(sorted(regions_dict.items()))\n",
    "    sorted_regions = np.array(sorted_regions_dict.values())\n",
    "    \n",
    "    sorted_rectangles = sorted_regions[:,1]\n",
    "    region_distances = [-sorted_rectangles[0][0]-sorted_rectangles[0][2]]\n",
    "    for x,y,w,h in sorted_regions[1:-1, 1]:\n",
    "        region_distances[-1] += x\n",
    "        region_distances.append(-x-w)\n",
    "    region_distances[-1] += sorted_rectangles[-1][0]\n",
    "    \n",
    "    return image_orig, sorted_regions[:, 0], region_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_test_original = load_image('images/cifre2.jpg')\n",
    "image_test = remove_noise(image_bin(image_gray(image_test_original)))\n",
    "\n",
    "selected_regions, letters, region_distances = select_roi(image_test_original.copy(), image_test)\n",
    "print 'Broj prepoznatih regiona:', len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_ann():\n",
    "    \n",
    "    ann = Sequential()\n",
    "    # Postavljanje slojeva neurona mreže 'ann'\n",
    "    ann.add(Dense(input_dim=784, output_dim=128,init=\"glorot_uniform\"))\n",
    "    ann.add(Activation(\"sigmoid\"))\n",
    "    ann.add(Dense(input_dim=128, output_dim=27,init=\"glorot_uniform\"))\n",
    "    ann.add(Activation(\"sigmoid\"))\n",
    "    return ann\n",
    "    \n",
    "def train_ann(ann, X_train, y_train):\n",
    "    X_train = np.array(X_train, np.float32)\n",
    "    y_train = np.array(y_train, np.float32)\n",
    "   \n",
    "    # definisanje parametra algoritma za obucavanje\n",
    "    sgd = SGD(lr=0.01, momentum=0.9)\n",
    "    ann.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "    # obucavanje neuronske mreze\n",
    "    ann.fit(X_train, y_train, nb_epoch=500, batch_size=1, verbose = 0, shuffle=False, show_accuracy = False) \n",
    "      \n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepoznavanje razmaka između slova i između reči u rečenici\n",
    "Kao rešenje moguće je koristiti K-means algoritam i klasifikovati razmak između regiona na dve grupe:\n",
    "* Razmak između slova u reči\n",
    "* Razmak između reči"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_result(outputs, alphabet, k_means):\n",
    "    '''\n",
    "    Funkcija određuje koja od grupa predstavlja razmak između reči, a koja između slova, i na osnovu\n",
    "    toga formira string od elemenata pronađenih sa slike.\n",
    "    Args:\n",
    "        outputs: niz izlaza iz neuronske mreže.\n",
    "        alphabet: niz karaktera koje je potrebno prepoznati\n",
    "        kmeans: obučen kmeans objekat\n",
    "    Return:\n",
    "        Vraća formatiran string\n",
    "    '''\n",
    "    # Odrediti indeks grupe koja odgovara rastojanju između reči, pomoću vrednosti iz k_means.cluster_centers_\n",
    "    w_space_group = max(enumerate(k_means.cluster_centers_), key = lambda x: x[1])[0]\n",
    "    result = alphabet[winner(outputs[0])]\n",
    "    for idx, output in enumerate(outputs[1:,:]):\n",
    "        # Iterativno dodavati prepoznate elemente kao u vežbi 2, alphabet[winner(output)]\n",
    "        # Dodati space karakter u slučaju da odgovarajuće rastojanje između dva slova odgovara razmaku između reči.\n",
    "        # U ovu svrhu, koristiti atribut niz k_means.labels_ koji sadrži sortirana rastojanja između susednih slova.\n",
    "        if (k_means.labels_[idx] == w_space_group):\n",
    "            result += ' '\n",
    "        result += alphabet[winner(output)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obučavanje veštačke neuronske mreže\n",
    "Naredni segment koda vrši učitavanje slike koja predstavlja obučavajući skup, definiše alfabet svih karaktera koji se nalaze na slici za obučavanje, redom sa leva na desno, kao i sam postupak obučavanja veštačke neuronske mreže."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_test_original_obucavanje = load_image('images/obucavajuciSkup.jpg')\n",
    "image_test_obucavanje = remove_noise(image_bin(image_gray(image_test_original_obucavanje)))\n",
    "\n",
    "selected_test_obucavanje, letters_obucavanje, region_distances_obucavanje = select_roi(image_test_original_obucavanje.copy(), image_test_obucavanje)\n",
    "region_distances_obucavanje = np.array(region_distances_obucavanje).reshape(len(region_distances_obucavanje), 1)\n",
    "k_means_test = KMeans(n_clusters=2, max_iter=2000, tol=0.00001, n_init=10)\n",
    "k_means_test.fit(region_distances_obucavanje)\n",
    "inputs_obucavanje = prepare_for_ann(letters_obucavanje)\n",
    "alphabet = ['a','s','d','f','g','h','j','k','l','č','ć','ž','š','p','o','i','u','z','t','r','e','c','v','b','n','m','đ']\n",
    "outputs_obucavanje = convert_output(alphabet)\n",
    "ann = create_ann()\n",
    "ann = train_ann(ann, inputs_obucavanje, outputs_obucavanje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predikcija na osnovu obučene mreže\n",
    "Naredni segment koda vrši predikciju, odnosno prepoznavanje simbola sa fotografije za testiranje. U ovoj fazi se koristi veštačka neuronska mreža koja je definisana u prethodnom koraku i na osnovu nje se vrši predikcija rezultata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_test_original = load_image('images/test1.jpg')\n",
    "image_test = remove_noise(image_bin(image_gray(image_test_original)))\n",
    "\n",
    "selected_regions_test, letters_test, region_distances_test = select_roi(image_test_original.copy(), image_test)\n",
    "region_distances_test = np.array(region_distances_test).reshape(len(region_distances_test), 1)\n",
    "k_means_test = KMeans(n_clusters=2, max_iter=2000, tol=0.00001, n_init=10)\n",
    "k_means_test.fit(region_distances_test)\n",
    "inputs_test = prepare_for_ann(letters_test)\n",
    "results_test = ann.predict(np.array(inputs_test, np.float32))\n",
    "print display_result(results_test, alphabet, k_means_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepoznavanje teksta koji se nalazi u više redova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
